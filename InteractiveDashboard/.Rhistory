mean(data) - qt(1 - alfa/2, n - 1) * sd(data) / sqrt(n)
mean(data) + qt(1 - alfa/2, n - 1) * sd(data) / sqrt(n)
#We are 95%  that the interval covers the true mean weight of ALL diamonds produced by this method
stest = sigma.test(data, conf.level = 1 - alfa)
z.test(data, sigma.x = sd(data), conf.level = 1 - alfa)
zsum.test(mean(data), sd(data), n, conf.level = 1 - alfa)
sqrt(stest$conf.int)
install.packages("BSDA")
#We are 95% that the interval ... covers the true variance of ALL of the weights of ALL diamonds produced by this method.
cig = na.omit(data_est["cigarettes"])
cig = cig[,1]
sigma = 0.7
mean(cig)
#material - all labs
signal = na.omit(data_est["signal"])
signal = signal[,1]
n = length(signal)
xbar = mean(signal)
# the mean intensity of all signals from location A is estimated by 19.3
alfa = 1 - 0.95
sigma = 3
z.test(signal, sigma, alfa)
# we are 95 % sure that the interval from 17.44 till 21.16 covers the true mean intensity of all signals sent from location a
n = 1200
mean = 4.7
sd = 2.2
data = rnorm(1200, mean, sd)
zsum.test(mean, sd, 1200)
#we are 95% sure that the interval from 4.57 to 4.82 minutes covers the true mean length of all phone calls made during midday.
#task7
variance = 25
sd = 5
alfa = 0.05
z = qnorm(1-alfa/2)
est_error = z * sd/sqrt(n) # =< 1
sqrt(n) >= z * sd
k = z * sd
n = ceil(k*k)
n = 97
#normally distributed random variable
#HOMEWORK TASK 6 !!!!!!!!!!!!!!!!!!!!!
lifetimes = na.omit(data_est["lifetime"])
lifetimes = lifetimes[,1]
#HOMEWORK TASK 8
est_error = 0.1
sd = 0.3
alfa = 0.1
z = qnorm(1-alfa/2)
n = z * sd / est_error
n = n*n
n = 25
alfa = 0.01
z = qnorm(1-alfa/2)
n = z * sd / est_error
n = n*n
n = 60
#task10
n = 100
T = 4
phat = T/n
# the proportion of all underfilled cans is estimated as 4% so more or less 4% cans will be underfilled
binom.test(T, n)
#we are 95% sure that the interval from 1.1% to 9.9% covers the true unknown proportion of all underfilled  cans.
alfa = 0.05
z = qnorm(1 - alfa/2)
L = phat-z*sqrt(phat*(1-phat)/n)
U = phat+z*sqrt(phat*(1-phat)/n)
est_err = (U-L)/2 + L
prop.test(T,n, correct=T)
#task9
n = 100
T = 3
phat = T/n
# the proportion of all down computers is estimated as 3% so more or less 3% of computers arent working
alfa = 0.05
z = qnorm(1 - alfa/2)
L = phat-z*sqrt(phat*(1-phat)/n)
U = phat+z*sqrt(phat*(1-phat)/n)
L
U
#we are 95% sure that the interval from 0% to 6.34% covers the true unknown proportion of all down computers
est_err = (U-L)/2 + L
binom.test(T, n)
prop.test(T,n, correct=T)
#task13
est_error = 0.05
alfa = 0.02
phat*(1-phat)/n = (est_err / qnorm(1 - alfa/2))**2
n = phat*(1-phat)/((est_err / qnorm(1 - alfa/2))**2)
k = est_err / qnorm(1 - alfa/2)
k = k*k
phat*(1-phat)/n = k
k*n = phat*(1-phat)
phat = 0.3
n = phat*(1-phat)/k
data_hip = read.csv('data_hip.csv', sep = ';')
wind = na.omit(data_hip["wind"])
wind = wind[,1]
alfa = 0.05
#HYPOTHESIS
#H0 mu <= 4          H1  mu > 4
mean(wind)
t.test(wind, mu = 4, alternative = 'greater')
xbar = mean(wind)
s = sd(wind)
mu0 = 4
(xbar - mu0)/(s/sqrt(length(wind)))
t = qt(1-alfa, length(wind)-1)
#test t belongs to critical region
#reject H0
#pvalue is the value of probability under which we base a decision
#if alpha is greater than p we reject the decision
COP = na.omit(data_hip["COP"])
COP = COP[,1]
alfa = 0.01
#Hypothesis H0  mu >= 3.5 H1 mu < 3.5
t.test(COP, mu = 3.5, alternative = 'less')
#alpha = 0.01   pvalue = 0.1521
#no reason to reject hypothesis
#on significance level 1% data does not confirm that the consumer is right
temperature = na.omit(data_hip["temperature"])
temperature = temperature[,1]
alpha = 0.01
sd = 2
#HYPOTHESIS
#H0 mu = 54   H1 mu =/= 54
z.test(temperature, sigma.x = 2, mu = 54, alternative="two.sided")
a = 1
for(i in flights){
hist(i, main=paste("histogram of year", substring(names(flights)[a], 2)), xlim = c(min(flights),max(flights)), col = 'hotpink', xlab = 'number of passengers', ylab = 'number of months')
a = a+1
}
par(mfrow = c(1,1))
d1 = data.frame(r1,r2,r4)
flights = read.csv("flights.csv", sep = ';')
d1 = data.frame(r1,r2,r4)
flights = read.csv("flights.csv", sep = ';')
lab = names(flights)
typeof(flights[1])
par(mfrow = c(3,2))
a = 1
source("~/lectures and such.R", echo=TRUE)
source("~/lectures and such.R", echo=TRUE)
r1 = rbinom(20, 10, 0.3)
r2 = rbinom(20, 10, 0.3)
mean(r1)
mean(r2)
var(r1)
var(r2)
mean(r1) / sd(r1)
quantile(r1, 0.1)
r3 = c(6, 7, 10, 5, 10, 12, 11, 7, 7, 9, 10, 8, 16, 11)
hist(r3, col="blue", breaks=c
(4, 8, 10, 14, 16))
#point series
table(r3)
#interval series
table(cut(r3, sqrt(length(r3))))
#lab3  = lecture2:
#ex1
x = c(-2, -1, 0, 2, 3)
p = c(0.1, 0.2, 0.3, 0.2, 0.2)
# POPRAWIC
hist(x, prob = TRUE)
expected = sum(x * p)
standardDev = sum(x*x*p) - expected ^ 2
sum((3*x+2) * p)
sum((3*x+2)^2 * p) - sum((3*x+2) * p)^2
#ex 7:
probF = 0.01
#P(X>2): 1 - F(a)
f = pbinom(2, 200, 0.01) # (less than q, size many tries, chance of success)
1 - f
pbinom(3, 200, 0.01)
set.seed(148260)
r1 = rbinom(12,30,0.3)
r2 = rbinom(12,30,0.2)
quantile(r1)
quantile(r2)
summary(r1)
summary(r2)
#interpretation of mean -> The average of rainy days a month in 2000 was 8, while in 2020 it was just below 6 days a month.
#interpretation of 1st quartile -> In 2000 in at least three months we could observe no more than 7 rainy days, and in at least nine months no more than 9 days a month.
#interpretation of 1st quartile -> In 2020 in at least three months we could observe no more than 7 rainy days, and in at least nine months no more than 8.25 days a month.
#interpretation of median -> In 2000 at least 6 months had 8.5 rainy days a month. In 2020 at least 6 months had 5 rainy days a month.
#In 2000 the number of rainy days per month varied between 6 and 10, while in 2020 the range has gone down to (1,11)
quantile(r1, probs = c(0.1,0.3,0.6,0.9))
quantile(r2, probs = c(0.1,0.3,0.6,0.9))
sd(r1)
sd(r2)
variability_index = sd(r1)/mean(r1)*100
variability_index
variability_index = sd(r2)/mean(r2)*100
variability_index
#variability (based on variability index) can be: 0-20 weak 20-40 medium 40-60 strong 60-100 very strong
#The amount of rainy days in 2000 deviated from the average by 1.9.
r = cbind(r1,r2)
summary(r)
quantile(r, probs = c(0.1,0.3,0.6,0.9))
mean(r)
rr = data.frame(r1,r2)
summary(rr)
mean(rr)
mean(rr$r1)
r1 = r1[1:8]
r2 = r2[1:8]
r3 = letters[1:8]
m1 = rbind(r1[1:8],r2[1:8],r3)
m1
d1 = data.frame(r1, r2, r3)
d1
mean(m1)
mean(d1)
mean(m1$r1)
mean(d1$r2)
summary(d1$r1)
summary(d1$r2)
r4 = c(1,2,3)
m1 = cbind(r1, r2, r4)
d1 = data.frame(r1,r2,r4)
flights = read.csv("flights.csv", sep = ';')
lab = names(flights)
typeof(flights[1])
par(mfrow = c(3,2))
a = 1
for(i in flights){
hist(i, main=paste("histogram of year", substring(names(flights)[a], 2)), xlim = c(min(flights),max(flights)), col = 'hotpink', xlab = 'number of passengers', ylab = 'number of months')
a = a+1
}
par(mfrow = c(1,1))
par(mfrow = c(1,1))
for(i in ncol(lab)){
lab[i] = substring(names(flights)[i], 2)
}
boxplot(flights, ylim = c(min(flights),max(flights)), col = 'royalblue')
notes = read.csv("notes.csv", sep = ';', dec = ',')
install.packages("BSDA")
install.packages("arm")
install.packages("teachingdemos")
install.packages("BSDA")
install.packages("arm")
install.packages("teachingdemos")
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
set.seed(148260)
r1 = rbinom(12,30,0.3)
r2 = rbinom(12,30,0.2)
quantile(r1)
quantile(r2)
summary(r1)
summary(r2)
#interpretation of mean -> The average of rainy days a month in 2000 was 8, while in 2020 it was just below 6 days a month.
#interpretation of 1st quartile -> In 2000 in at least three months we could observe no more than 7 rainy days, and in at least nine months no more than 9 days a month.
#interpretation of 1st quartile -> In 2020 in at least three months we could observe no more than 7 rainy days, and in at least nine months no more than 8.25 days a month.
#interpretation of median -> In 2000 at least 6 months had 8.5 rainy days a month. In 2020 at least 6 months had 5 rainy days a month.
#In 2000 the number of rainy days per month varied between 6 and 10, while in 2020 the range has gone down to (1,11)
quantile(r1, probs = c(0.1,0.3,0.6,0.9))
quantile(r2, probs = c(0.1,0.3,0.6,0.9))
sd(r1)
sd(r2)
variability_index = sd(r1)/mean(r1)*100
variability_index
variability_index = sd(r2)/mean(r2)*100
variability_index
#variability (based on variability index) can be: 0-20 weak 20-40 medium 40-60 strong 60-100 very strong
#The amount of rainy days in 2000 deviated from the average by 1.9.
r = cbind(r1,r2)
summary(r)
quantile(r, probs = c(0.1,0.3,0.6,0.9))
mean(r)
rr = data.frame(r1,r2)
summary(rr)
mean(rr)
mean(rr$r1)
r1 = r1[1:8]
r2 = r2[1:8]
r3 = letters[1:8]
m1 = rbind(r1[1:8],r2[1:8],r3)
m1
d1 = data.frame(r1, r2, r3)
d1
mean(m1)
mean(d1)
mean(m1$r1)
mean(d1$r2)
summary(d1$r1)
summary(d1$r2)
r4 = c(1,2,3)
m1 = cbind(r1, r2, r4)
d1 = data.frame(r1,r2,r4)
flights = read.csv("flights.csv", sep = ';')
lab = names(flights)
typeof(flights[1])
par(mfrow = c(3,2))
a = 1
for(i in flights){
hist(i, main=paste("histogram of year", substring(names(flights)[a], 2)), xlim = c(min(flights),max(flights)), col = 'hotpink', xlab = 'number of passengers', ylab = 'number of months')
a = a+1
}
par(mfrow = c(1,1))
for(i in ncol(lab)){
lab[i] = substring(names(flights)[i], 2)
}
boxplot(flights, ylim = c(min(flights),max(flights)), col = 'royalblue')
notes = read.csv("notes.csv", sep = ';', dec = ',')
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R")
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
#hist()
plot(pnorm(9975, nmu, sqrt(n), sigma), type="l")
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
x = rnorm(n, e, sd)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R")
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R")
source("~/TEST.R")
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/TEST.R", echo=TRUE)
source("~/lab7.R", echo=TRUE)
tires = c(53417, 51000, 48583, 53000, 49000, 51000, 52000, 50000)
sd(tires)
s = sd(tires)
tires = c(53417, 51000, 48583, 53000, 49000, 51000, 52000, 50000)
s = sd(tires)
n = 8
a = 0.05
t = t.test (tires, alternative="greater", mu = 50000,
conf.level = 0.95)
View(t)
view(t)
t = t.test (tires, alternative="greater", mu = 50000,
conf.level = 0.95)
t = t.test (tires, alternative="greater", mu = 50000, conf.level = 0.95)
t = t.test (tires, alternative="greater", mu = 50000, conf.level = 0.95)
t.test (tires, alternative="greater", mu = 50000, conf.level = 0.95)
time = c(10,10,15,12,9,8,4,10,3,4,6,5,7,8,13)
sigma.test(time, alternative="less", sigmasq = 25, conf.level = 0.95)
install.packages("TeachingDemos")
sigma.test(time, alternative="less", sigmasq = 25, conf.level = 0.95)
H = (607237, 961181, 165203)
barplot (H)
H = (607237; 961181; 165203)
H = c(607237, 961181, 165203)
barplot (H)
barplot (H, "candidates")
barplot (H, 'candidates')
barplot (H, xlab="candidates")
barplot (H, xlab="candidates", ylab = "vote count")
barplot (H, xlab="candidates", ylab = "vote count"
names.arg=H)
barplot (H, xlab="candidates", ylab = "vote count"
names.arg=H)
H <- c (6,11,27,2,44)
D <- c("Jan","feb","Mar","Apr","May")
barplot(H,names.arg=D,xlab="Month",ylab="sale",col="Red",main="Salechart",border="yellow")
H = c(607237, 961181, 165203)
H = c(607237, 961181, 165203)
Hper = H / H.sum()
Hper = H / sum(H)
barplot (Hper, xlab="candidates", ylab = "vote count"
names.arg=H)
barplot (Hper, xlab="candidates", ylab = "vote count",
names.arg=H)
Hper = H / sum(H) * 100
barplot (Hper, xlab="candidates", ylab = "percent of votes",
names.arg=H)
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H)
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H)
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H, col = c("blue", "red", "green"))
H = sort(c(607237, 961181, 165203))
Hper = H / sum(H) * 100
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H, col = c("blue", "red", "green"))
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H, col = c("blue", "green", "red"))
barplot (Hper, xlab="candidates", ylab = "% of votes",
names.arg=H, col = c("red", "blue", "green"))
barplot (Hper, xlab="candidates (vote count)", ylab = "% of votes",
names.arg=H, col = c("red", "blue", "green"))
H = sort(c(607237, 961181, 165203), desc=TRUE)
Hper = H / sum(H) * 100
barplot (Hper, xlab="candidates (vote count)", ylab = "% of votes",
names.arg=H, col = c("red", "blue", "green"))
H = sort(c(607237, 961181, 165203), decreasing=TRUE)
Hper = H / sum(H) * 100
barplot (Hper, xlab="candidates (vote count)", ylab = "% of votes",
names.arg=H, col = c("red", "blue", "green"))
data1 = read.csv("C:\Users\Wojciech\Desktop\Dataset\Correlations.csv", sep = ";", dec = '.')
data1 = read.csv("Correlations.csv", sep = ";", dec = '.')
data1 = read.csv("Correlations.csv", sep = ";", dec = '.')
shiny::runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
data <- read.csv("dnd-spells.csv")
library(shiny)
data <- read.csv("dnd-spells.csv")
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
shiny::runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
runApp('GitHub/Interactive-Dashboard/InteractiveDashboard')
